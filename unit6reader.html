<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visual Communication</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #e0f2fe;
            color: #1a202c;
        }
        .container {
            max-width: 900px;
            padding: 2rem;
        }
        .card {
            background-color: #fff;
            border-radius: 1.5rem;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            padding: 2rem;
        }
        .paragraph {
            opacity: 0;
            max-height: 0;
            overflow: hidden;
            transition: opacity 0.5s ease-in-out, max-height 0.5s ease-in-out;
        }
        .paragraph-visible {
            opacity: 1;
            max-height: 1000px;
            margin-bottom: 1.5rem;
        }
        button {
            background-color: #3b82f6;
            color: #fff;
            padding: 0.75rem 1.5rem;
            border-radius: 9999px;
            font-weight: bold;
            transition: background-color 0.3s ease;
        }
        button:hover {
            background-color: #2563eb;
        }
        button:disabled {
            background-color: #9ca3af;
            cursor: not-allowed;
        }
        #loading-indicator {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3498db;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .clickable-term {
            font-weight: bold;
            cursor: pointer;
            text-decoration: underline;
            text-decoration-color: #f9a8d4;
            text-underline-offset: 4px;
            transition: text-decoration-color 0.3s ease;
        }
        .clickable-term:hover {
            text-decoration-color: #ec4899;
        }
        .highlighted {
            background-color: #fef08a;
        }
        /* Modal Styles */
        .modal-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.6);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }
        .modal-content {
            background-color: #fff;
            padding: 2rem;
            border-radius: 1rem;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.2);
            max-width: 500px;
            text-align: center;
        }
    </style>
</head>
<body class="min-h-screen flex items-center justify-center p-6">

    <div class="container mx-auto">
        <div class="card">
            <h1 class="text-4xl md:text-5xl font-bold text-center mb-8 text-blue-800">Visual Communication üé®üëÅÔ∏è</h1>
            <div id="text-container">
                <p id="p1" class="paragraph text-lg leading-relaxed">Stories have been a <span class="clickable-term highlighted" data-definition="Having a strong purpose or meaning.">meaningful</span> form of communication throughout human history. Do you remember a time when a family member told you a story without reading it from a book? <span class="clickable-term highlighted" data-definition="Stories told by speaking, not reading from a book.">Oral stories</span> are a part of every culture, and they allow us to pass traditions and values from one generation to the next. <span class="clickable-term highlighted" data-definition="Stories told with drawings or pictures instead of words.">Visual stories</span> have also been told in a variety of ways for thousands of years. Researchers have found rocks that were decorated by humans more than 10,000 years ago in caves around the world. These drawings were created with mineral pigments, and they told a story of daily life, including events such as hunts or animal migrations. Although the rocks had only simple linear <span class="clickable-term highlighted" data-definition="A repeated drawing or shape.">patterns</span>, the patterns had meaning. And it‚Äôs meaning that creates a story.</p>
                <p id="p2" class="paragraph text-lg leading-relaxed">People began painting on cave walls around 40,000 years ago. As time went on, painted <span class="clickable-term highlighted" data-definition="Drawings of a person or thing.">images</span> appeared on everything from <span class="clickable-term highlighted" data-definition="Objects made from baked clay, such as bowls or pots.">pottery</span> to <span class="clickable-term highlighted" data-definition="A strong fabric used to paint pictures.">canvas</span>. Painting is a fairly permanent way to <span class="clickable-term highlighted" data-definition="To show or signify something.">represent</span> information. Because painted walls and objects have lasted for thousands of years, they give us a window into the past. Through this window we can see the stories of ancient Egyptians on the walls of their <span class="clickable-term highlighted" data-definition="A large room or building for burying dead people.">tombs</span>. We can also see scenes from Renaissance Europe, showing the lives of people from kings to <span class="clickable-term highlighted" data-definition="Ordinary people who are not of royalty.">commoners</span>. These paintings allow us to be <span class="clickable-term highlighted" data-definition="A person who watches an event happen.">witnesses</span> to history.</p>
                <p id="p3" class="paragraph text-lg leading-relaxed">In the early nineteenth century, French artist Louis-Jacques-Mande Daguerre introduced a device that provided another way to tell visual stories: the <i>daguerreotype</i>. This early camera was first used to take <span class="clickable-term highlighted" data-definition="Pictures of a person, especially their face.">portraits</span>. Photography with other subjects eventually became popular, but it took a while. At first people were afraid of a camera‚Äôs ability to capture real life!</p>
                <p id="p4" class="paragraph text-lg leading-relaxed">Today photographers like Ami Vitale use photos to <span class="clickable-term highlighted" data-definition="To show or describe something.">portray</span> how people live. Ami presents her photos in ways that create certain responses from her <span class="clickable-term highlighted" data-definition="The people who watch or listen to something.">audience</span>, such as <span class="clickable-term highlighted" data-definition="A strong feeling of being angry or mad.">anger</span> or <span class="clickable-term highlighted" data-definition="A strong feeling of surprise or disturbance.">shock</span>. ‚ÄúPhotography creates change,‚Äù she says. Ami hopes that by telling her <span class="clickable-term highlighted" data-definition="The main person or thing in a photo or story.">subjects‚Äô</span> stories visually, she‚Äôll get people to realize that we‚Äôre more alike than we are different. This will create a greater <span class="clickable-term highlighted" data-definition="The ability to know and feel for something.">understanding</span> among people around the world.</p>
            </div>

            <div class="flex flex-col sm:flex-row justify-center items-center mt-8 space-y-4 sm:space-y-0 sm:space-x-4">
                <button id="show-next-btn" class="w-full sm:w-auto">Show Next Paragraph</button>
                <button id="read-aloud-btn" class="w-full sm:w-auto">Read Aloud</button>
                <div id="loading-indicator" class="hidden"></div>
            </div>
            <div id="message-box" class="mt-4 text-center text-red-500 font-bold"></div>
        </div>
    </div>

    <!-- The Modal Pop-up -->
    <div id="definition-modal" class="modal-overlay hidden" onclick="closeModal(event)">
        <div class="modal-content">
            <h3 id="modal-term" class="text-2xl font-bold mb-2"></h3>
            <p id="modal-definition" class="text-lg"></p>
        </div>
    </div>

    <script>
        const apiKey = "";
        const showNextBtn = document.getElementById('show-next-btn');
        const readAloudBtn = document.getElementById('read-aloud-btn');
        const loadingIndicator = document.getElementById('loading-indicator');
        const messageBox = document.getElementById('message-box');
        const modal = document.getElementById('definition-modal');
        const modalTerm = document.getElementById('modal-term');
        const modalDefinition = document.getElementById('modal-definition');
        
        let audioPlayer = null;
        let audioUrl = null;
        let paragraphIndex = 0;
        let paragraphs = [];

        window.onload = function() {
            paragraphs = [document.getElementById('p1'), document.getElementById('p2'), document.getElementById('p3'), document.getElementById('p4')];
            if (paragraphs.length > 0) {
                paragraphs[0].classList.add('paragraph-visible');
                paragraphIndex = 1;
            }

            document.getElementById('text-container').addEventListener('click', (event) => {
                if (event.target.classList.contains('clickable-term')) {
                    showDefinition(event.target.textContent, event.target.dataset.definition);
                }
            });
        };

        showNextBtn.addEventListener('click', () => {
            if (audioPlayer) {
                audioPlayer.pause();
                audioPlayer = null;
                if (audioUrl) {
                    URL.revokeObjectURL(audioUrl);
                    audioUrl = null;
                }
                readAloudBtn.textContent = 'Read Aloud';
                readAloudBtn.disabled = false;
            }

            if (paragraphIndex < paragraphs.length) {
                paragraphs[paragraphIndex].classList.add('paragraph-visible');
                paragraphIndex++;
            }
            if (paragraphIndex >= paragraphs.length) {
                showNextBtn.disabled = true;
            }
        });

        readAloudBtn.addEventListener('click', async () => {
            if (audioPlayer && !audioPlayer.paused) {
                audioPlayer.pause();
                readAloudBtn.textContent = 'Continue Reading';
            } else if (audioPlayer && audioPlayer.paused) {
                audioPlayer.play();
                readAloudBtn.textContent = 'Pause Reading';
            } else {
                const currentParagraphIndex = paragraphIndex - 1;
                if (currentParagraphIndex < 0 || currentParagraphIndex >= paragraphs.length) {
                    showMessage("There is no text to read. Click 'Show Next Paragraph' first.");
                    return;
                }
                
                const paragraphToRead = paragraphs[currentParagraphIndex];
                const cleanText = paragraphToRead.innerText;
                
                if (cleanText.trim() === '') {
                    showMessage("This paragraph is empty. Click 'Show Next Paragraph' to load another one.");
                    return;
                }

                readAloudBtn.textContent = 'Loading...';
                readAloudBtn.disabled = true;
                loadingIndicator.classList.remove('hidden');

                try {
                    const payload = {
                        contents: [{
                            parts: [{ text: cleanText }]
                        }],
                        generationConfig: {
                            responseModalities: ["AUDIO"],
                            speechConfig: {
                                voiceConfig: { prebuiltVoiceConfig: { voiceName: "Iapetus" } }
                            }
                        },
                        model: "gemini-2.5-flash-preview-tts"
                    };

                    const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
                    
                    let response = await fetch(apiUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    if (!response.ok) {
                        throw new Error(`API call failed with status: ${response.status}`);
                    }

                    let result = await response.json();
                    let part = result?.candidates?.[0]?.content?.parts?.[0];
                    let audioData = part?.inlineData?.data;
                    let mimeType = part?.inlineData?.mimeType;

                    if (audioData && mimeType && mimeType.startsWith("audio/")) {
                        const sampleRate = parseInt(mimeType.match(/rate=(\d+)/)[1], 10);
                        const pcmData = base64ToArrayBuffer(audioData);
                        const pcm16 = new Int16Array(pcmData);
                        const wavBlob = pcmToWav(pcm16, sampleRate);
                        
                        if (audioUrl) {
                            URL.revokeObjectURL(audioUrl);
                        }

                        audioUrl = URL.createObjectURL(wavBlob);
                        
                        audioPlayer = new Audio(audioUrl);
                        audioPlayer.play();
                        readAloudBtn.textContent = 'Pause Reading';

                        audioPlayer.onended = () => {
                            readAloudBtn.textContent = 'Read Aloud';
                            audioPlayer = null;
                            URL.revokeObjectURL(audioUrl);
                            audioUrl = null;
                        };

                    } else {
                        throw new Error('Invalid audio data received.');
                    }

                } catch (error) {
                    showMessage("Sorry, I couldn't read the text. Please try again.");
                    console.error("Audio generation error:", error);
                } finally {
                    readAloudBtn.disabled = false;
                    loadingIndicator.classList.add('hidden');
                }
            }
        });

        function showMessage(msg) {
            messageBox.textContent = msg;
            setTimeout(() => {
                messageBox.textContent = '';
            }, 5000);
        }

        function showDefinition(term, definition) {
            modalTerm.textContent = term;
            modalDefinition.textContent = definition;
            modal.classList.remove('hidden');
        }

        function closeModal(event) {
            if (event.target === modal) {
                modal.classList.add('hidden');
            }
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function pcmToWav(pcmData, sampleRate) {
            const dataLength = pcmData.length * 2;
            const buffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(buffer);
            let offset = 0;

            function writeString(str) {
                for (let i = 0; i < str.length; i++) {
                    view.setUint8(offset++, str.charCodeAt(i));
                }
            }

            function writeUint32(val) {
                view.setUint32(offset, val, true);
                offset += 4;
            }

            function writeUint16(val) {
                view.setUint16(offset, val, true);
                offset += 2;
            }

            writeString('RIFF');
            writeUint32(36 + dataLength);
            writeString('WAVE');
            writeString('fmt ');
            writeUint32(16);
            writeUint16(1);
            writeUint16(1);
            writeUint32(sampleRate);
            writeUint32(sampleRate * 2);
            writeUint16(2);
            writeUint16(16);
            writeString('data');
            writeUint32(dataLength);

            for (let i = 0; i < pcmData.length; i++) {
                view.setInt16(offset, pcmData[i], true);
                offset += 2;
            }

            return new Blob([view], { type: 'audio/wav' });
        }
    </script>
</body>
</html>
